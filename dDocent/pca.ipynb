{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../include_utils/\")\n",
    "\n",
    "import ipyparallel as ipp\n",
    "import os, time\n",
    "import include_utils as u\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import vcf\n",
    "from sklearn import preprocessing\n",
    "from subprocess import Popen, PIPE\n",
    "import seaborn as sns\n",
    "from IPython.display import FileLink\n",
    "#import urllib2\n",
    "import urllib.request as urllib2\n",
    "import urllib\n",
    "import dill\n",
    "import traceback\n",
    "from pandas import Series, DataFrame\n",
    "import gzip\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from collections import OrderedDict, namedtuple\n",
    "import operator\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "from IPython.display import FileLink, FileLinks, display\n",
    "\n",
    "samtools = \"/home/cfriedline/gpfs/src/samtools-1.3/samtools\"\n",
    "bcftools = \"/home/cfriedline/gpfs/src/bcftools-1.3/bcftools\"\n",
    "picard = \"/home/cfriedline/gpfs/src/broadinstitute-picard-03a1d72/dist/picard.jar\"\n",
    "java = \"/home/cfriedline/g/src/jdk1.8.0_60/bin/java\"\n",
    "perl = \"/home/cfriedline/gpfs/opt/ActivePerl-5.18/bin/perl\"\n",
    "\n",
    "vcfutils = \"perl /home/cfriedline/g/src/bcftools-1.3/vcfutils.pl\"\n",
    "vcftools = \"/home/cfriedline/bin/vcftools\"\n",
    "bcftools = \"/home/cfriedline/gpfs/src/bcftools-1.3/bcftools\"\n",
    "tabix = \"/home/cfriedline/gpfs/src/htslib-1.3/tabix\"\n",
    "bgzip = \"/home/cfriedline/gpfs/src/htslib-1.3/bgzip\"\n",
    "\n",
    "\n",
    "def setup_r():\n",
    "    os.environ['R_HOME'] = '/home/cfriedline/g/R3/lib64/R'\n",
    "    os.environ['LD_LIBRARY_PATH'] = \"%s/lib:%s:%s\" % (os.environ['R_HOME'], \n",
    "                                                   os.environ['LD_LIBRARY_PATH'],\n",
    "                                                     \"/home/cfriedline/lib64\")\n",
    "\n",
    "setup_r()\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "r = robjects.r\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%reload_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ni_dir = \"/home/cfriedline/eckertlab/Mitra/dDocent\"\n",
    "#imp_dir = \"/home/cfriedline/eckertlab/Mitra/mapping/split_parallel/collapsed/work/samtools1.3/beagle40/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notimputed_vcf_gz = os.path.join(ni_dir, \"good_snps.recode.vcf.gz\")\n",
    "#imputed_vcf_gz = os.path.join(imp_dir, \"isect_snps.recode.vcf.gz_sorted.vcf.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vcfs = [notimputed_vcf_gz]#, imputed_vcf_gz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for v in vcfs:\n",
    "    !$vcftools --gzvcf $v --012 --out $v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12s = [\"%s.012\" % x for x in vcfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_z12_df(z12_file):\n",
    "    indv_file = \"%s.indv\" % z12_file\n",
    "    pos_file = \"%s.pos\" % z12_file\n",
    "    z12_data = []\n",
    "    for i, line in enumerate(open(z12_file)):\n",
    "        line = line.strip()\n",
    "        line = [int(x) for x in line.split(\"\\t\")]\n",
    "        z12_data.append(np.array(line))\n",
    "    z12_data = np.array(z12_data)\n",
    "    p = pd.read_csv(pos_file, sep=\"\\t\", names=['contig', 'pos'])\n",
    "    i = pd.read_csv(indv_file, names=['sample_name'])\n",
    "    df = pd.DataFrame(z12_data)\n",
    "    df = df.drop(0, axis=1)\n",
    "    df.columns = p.apply(lambda x: \"%s-%s\" % (x.contig, x.pos), axis=1)\n",
    "    df.index = [x.upper() for x in i.sample_name]\n",
    "    return df\n",
    "z12_dfs = [get_z12_df(x) for x in z12s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_pop(row):\n",
    "    if row.name.startswith(\"LP\"):\n",
    "        return row.name[0:2]\n",
    "    return row.name[0:3]\n",
    "\n",
    "def assign_population(df):\n",
    "    df['population'] = df.apply(lambda x: extract_pop(x), axis=1)\n",
    "[assign_population(x) for x in z12_dfs];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x.shape for x in z12_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_correction(n):\n",
    "    #for finite sample size\n",
    "    return (2*n)/(2*n-1)\n",
    "\n",
    "def get_allele_freqs(locus, debug):\n",
    "    c = locus[locus != -1].value_counts()\n",
    "    total_alleles = 2.0*sum(c)\n",
    "    num_individuals = sum(c)\n",
    "    P = 0\n",
    "    Q = 0\n",
    "    PQ = 0\n",
    "    if 0 in c:\n",
    "        P = 2*c[0]\n",
    "    if 2 in c:\n",
    "        Q = 2*c[2]\n",
    "    if 1 in c:\n",
    "        PQ = c[1]\n",
    "    P += PQ\n",
    "    Q += PQ\n",
    "    if total_alleles == 0:\n",
    "        return None\n",
    "    p = P/total_alleles\n",
    "    q = Q/total_alleles\n",
    "    assert p + q == 1.0\n",
    "    He = 2 * p * q * get_correction(num_individuals)\n",
    "    Ho = PQ*1.0/num_individuals\n",
    "    Fis = 1 - (Ho/He)\n",
    "    #print p, q, He, Ho, Fis\n",
    "    \n",
    "        \n",
    "    ret = pd.Series({\"p\":p, \n",
    "                      \"q\":q,\n",
    "                      \"P\":P,\n",
    "                      \"Q\":Q,\n",
    "                      \"He\":He,\n",
    "                      \"Ho\":Ho, \n",
    "                      \"Fis\":Fis})\n",
    "    if debug:\n",
    "        print(ret)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allele_freqs = [x.ix[:,:-1].apply(get_allele_freqs, args=(False,)) for x in z12_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x.shape for x in allele_freqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mafs = [x.apply(lambda x: min(x[\"p\"], x[\"q\"])) for x in allele_freqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mafs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mafs[0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def swap_alleles(locus, af):\n",
    "    if \"_\" in locus.name:\n",
    "        locus_id = locus.name\n",
    "        freqs = af[locus_id]\n",
    "        maf = min(freqs[\"p\"], freqs[\"q\"])\n",
    "        if maf == freqs[\"p\"]:\n",
    "            return locus.replace({0:2,2:0})\n",
    "        return locus\n",
    "    else:\n",
    "        return locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped = []\n",
    "for i, z12 in enumerate(z12_dfs):\n",
    "    z12_swapped.append(z12.apply(swap_alleles, args=(allele_freqs[i],)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_dfs[0].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allele_freqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped[0].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_id = {}\n",
    "i = 1\n",
    "for p in sorted(z12_dfs[0]['population'].unique()):\n",
    "    pop_id[p] = i\n",
    "    i+=1\n",
    "pop_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pops = pd.read_csv(\"~/eckertlab/Mitra/Pops.txt\", sep=\"\\t\").drop_duplicates()\n",
    "\n",
    "def get_species_label(row):\n",
    "    return pops[pops.Pop==row.population].Species.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_popid(series):\n",
    "    series['popid'] = pop_id[series['population']]\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped = [x.apply(assign_popid, axis=1) for x in z12_swapped]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z12_swapped[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_df(ni_dir, \"z12_swapped\", z12_swapped[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def center_and_standardize_value(val, u, var):\n",
    "    if val == -1:\n",
    "        return 0.0\n",
    "    return (val-u)/np.sqrt(var)\n",
    "\n",
    "def center_and_standardize(locus, af):\n",
    "    if \"_\" in locus.name:\n",
    "        #locus_id = int(locus.name[1:])\n",
    "        locus_id = locus.name\n",
    "        freqs = af[locus_id]\n",
    "        maf = min(freqs[\"p\"], freqs[\"q\"])\n",
    "        var = maf*(1-maf)\n",
    "        u = np.mean([x for x in locus if x != -1])\n",
    "        return locus.apply(center_and_standardize_value, args=(u, var))\n",
    "    return locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std = []\n",
    "for i, df in enumerate(z12_swapped):\n",
    "    pca_std.append(df.apply(center_and_standardize, args=(allele_freqs[i],)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, df in enumerate(pca_std):\n",
    "    df['species'] = df.apply(get_species_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data = [x.ix[:,:-3] for x in pca_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data[0].ix[:,0:10].apply(np.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data_ni = pca_std_data[0]\n",
    "#pca_std_data_imp = pca_std_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data_ni.shape#, pca_std_data_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_std_data_ni.to_csv(os.path.join(ni_dir, \"pca_std_data.txt\"), header=True, index=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(data.table)\n",
    "ni_dir = '/home/cfriedline/eckertlab/Mitra/dDocent'\n",
    "data_ni = fread(paste(ni_dir, '/pca_std_data.txt', sep=''), sep=\"\\t\", data.table=F)\n",
    "rownames(data_ni) = data_ni$V1\n",
    "\n",
    "drops = c(\"V1\")\n",
    "data_ni = data_ni[,!(names(data_ni) %in% drops)]\n",
    "res_ni = prcomp(data_ni, scale=F, center=F)\n",
    "rownames(res_ni$x) = rownames(data_ni)\n",
    "\n",
    "fname = 'pca_res.rds'\n",
    "ni = paste(ni_dir, \"/\", fname, sep='')\n",
    "saveRDS(res_ni, ni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r(\"res_ni = readRDS('%s/pca_res.rds')\" % ni_dir);\n",
    "#r(\"res_imp = readRDS('%s/pca_res.rds')\" % imp_dir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_pca_x(res):\n",
    "    x = pd.DataFrame(pandas2ri.ri2py(res.rx2(\"x\")))\n",
    "    x.index = res.rx2(\"x\").names[0]\n",
    "    x.columns = res.rx2(\"x\").names[1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(r('res_ni').rx2('x').names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary = r('summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prcomp_res = [x for x in [r['res_ni']]]#, r['res_imp']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_x = [get_pca_x(x) for x in [r['res_ni']]]#, r['res_imp']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_x[0].index = pca_std_data_ni.index\n",
    "#pca_x[1].index = pca_std_data_imp.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std[0].species.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "norm = mcolors.Normalize(min(pop_id.values()), max(pop_id.values()))\n",
    "\n",
    "def get_prop_var_from_summary(res, pc):\n",
    "    return summary(res).rx(\"importance\")[0].rx(2,pc)[0]\n",
    "\n",
    "def plot_pca_pop(key, pca_std, pca_std_data, pca_x, prcomp_res, x, y):\n",
    "    joined = pca_std.join(pca_x)\n",
    "    legend = {}\n",
    "    for row in joined.iterrows():\n",
    "        pop = row[1]['population']\n",
    "        n = norm(pop_id[pop])\n",
    "        color = cm.rainbow(n)\n",
    "        legend[pop] = color\n",
    "        plt.scatter(row[1]['PC%d' % x], \n",
    "                    row[1]['PC%d' % y], \n",
    "                    s=50, \n",
    "                    c=color)\n",
    "    fig = plt.gcf()\n",
    "    ax = plt.gca()\n",
    "    cmap = plt.get_cmap()\n",
    "    fig.set_size_inches(10,8)\n",
    "    plt.title(\"PCA of n=%d samples on %d dDocent loci (%s)\" % (len(joined), len(pca_std_data.columns), key))\n",
    "    plt.xlabel(\"PC{} ({})\".format(x, get_prop_var_from_summary(prcomp_res, x)))\n",
    "    plt.ylabel(\"PC{} ({})\".format(y, get_prop_var_from_summary(prcomp_res, y)))\n",
    "\n",
    "    handles = []\n",
    "    for pop in sorted(legend):\n",
    "        handles.append(mpatches.Patch(color=legend[pop], label=pop))\n",
    "    ax.legend(handles=handles, bbox_to_anchor=(1.25, .9), ncol=2)\n",
    "    \n",
    "    out_file = \"{}_{}_{}_pop.pdf\".format(key.replace(\" \", \"_\"), x, y)\n",
    "    \n",
    "    plt.savefig(out_file)\n",
    "    plt.show()\n",
    "    return out_file\n",
    "\n",
    "def plot_pca_spp(key, pca_std, pca_std_data, pca_x, prcomp_res, x, y):\n",
    "    joined = pca_std.join(pca_x)\n",
    "    legend = {'SWWP': 'blue', 'PA': 'orange', 'PF': 'green'}\n",
    "    for row in joined.iterrows():\n",
    "        pop = row[1]['population']\n",
    "        plt.scatter(row[1]['PC%d' % x], row[1]['PC%d' % y], s=50, c=legend[row[1].species])\n",
    "    fig = plt.gcf()\n",
    "    ax = plt.gca()\n",
    "    cmap = plt.get_cmap()\n",
    "    fig.set_size_inches(10,8)\n",
    "    plt.title(\"PCA of n=%d samples on %d dDocent loci (%s)\" % (len(joined), len(pca_std_data.columns), key))\n",
    "    plt.xlabel(\"PC{} ({})\".format(x, get_prop_var_from_summary(prcomp_res, x)))\n",
    "    plt.ylabel(\"PC{} ({})\".format(y, get_prop_var_from_summary(prcomp_res, y)))\n",
    "\n",
    "    out_file = \"{}_{}_{}_spp.pdf\".format(key.replace(\" \", \"_\"), x, y)\n",
    "    \n",
    "    handles = []\n",
    "    for pop in sorted(legend):\n",
    "        handles.append(mpatches.Patch(color=legend[pop], label=pop))\n",
    "    ax.legend(handles=handles, bbox_to_anchor=(1.17, .9), ncol=1)\n",
    "    \n",
    "    plt.savefig(out_file)\n",
    "    plt.show()\n",
    "    return out_file\n",
    "\n",
    "for i, key in enumerate([\"not imputed\"]):\n",
    "    f = plot_pca_spp(key, pca_std[i], pca_std_data[i], pca_x[i], prcomp_res[i], 1, 2)\n",
    "    display(FileLink(f))\n",
    "    f = plot_pca_spp(key, pca_std[i], pca_std_data[i], pca_x[i], prcomp_res[i], 3, 4)\n",
    "    display(FileLink(f))\n",
    "    f = plot_pca_pop(key, pca_std[i], pca_std_data[i], pca_x[i], prcomp_res[i], 1, 2)\n",
    "    display(FileLink(f))\n",
    "    f = plot_pca_pop(key, pca_std[i], pca_std_data[i], pca_x[i], prcomp_res[i], 3, 4)\n",
    "    display(FileLink(f))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def missing(locus):\n",
    "    c = len(locus[locus == -1])\n",
    "    return c/len(locus)\n",
    "missing = z12_dfs[0].apply(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(pd.DataFrame(missing[:-1].describe()).apply(np.round, args=(2,)).to_csv(header=False, sep=\"=\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(missing, kde=False, bins=100)\n",
    "plt.title(\"dDocent calls missing across individuals\")\n",
    "plt.text(0.01, 500, pd.DataFrame(missing[:-1].describe()).apply(np.round, args=(2,)).to_csv(header=False, sep=\"=\"))\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_df(dirname, fname, df):\n",
    "    f = os.path.join(dirname, \"%s.txt\" % fname) \n",
    "    df.to_csv(f, \n",
    "              header=True,\n",
    "              index=True,\n",
    "              sep=\"\\t\")\n",
    "    print(\"saved %s\" % f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(data.table)\n",
    "ni_dir ='/home/cfriedline/eckertlab/Mitra/mapping/split_parallel/collapsed/work/samtools1.3/'\n",
    "imp_dir = '/home/cfriedline/eckertlab/Mitra/mapping/split_parallel/collapsed/work/samtools1.3/beagle40/'\n",
    "data_ni = fread(paste(ni_dir, '/pca_std_data.txt', sep=''), sep=\"\\t\", data.table=F)\n",
    "data_imp = fread(paste(imp_dir, '/pca_std_data.txt', sep=''), sep=\"\\t\", data.table=F)\n",
    "rownames(data_ni) = data_ni$V1\n",
    "rownames(data_imp) = data_imp$V1\n",
    "drops = c(\"V1\")\n",
    "data_ni = data_ni[,!(names(data_ni) %in% drops)]\n",
    "data_imp = data_imp[,!(names(data_imp) %in% drops)]\n",
    "source(\"tw_calc.R\")\n",
    "test=read.table(\"twtable\", header=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "tw_ni = TWcalc(as.matrix(data_ni),20)\n",
    "tw_imp = TWcalc(as.matrix(data_imp),20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tws = [r(\"tw_ni[[2]]\"), r(\"tw_imp[[2]]\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sig_tracywidom(tw_p):\n",
    "    ps = []\n",
    "    for i, p in enumerate(tw_p):\n",
    "        if p > 0.05:\n",
    "            print(i, p)\n",
    "            break\n",
    "        else:\n",
    "            ps.append(p)\n",
    "    return len(ps), ps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tw_num = [get_sig_tracywidom(x) for x in tws]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracy-Widom\n",
    "\n",
    "```\n",
    "Not imputed: 13\n",
    "Imputed: 15\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_cov = [None]*2\n",
    "pca_cov[0] = pca_x[0].ix[:,0:tw_num[0][0]]\n",
    "pca_cov[1] = pca_x[1].ix[:,0:tw_num[1][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x.shape for x in pca_cov]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d, f in zip([ni_dir, imp_dir], pca_cov):\n",
    "    save_df(d, 'pca_cov', f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pca_std_pheno = pheno.join(pca_cov, how=\"inner\").join(pca_maf.ix[:,:-2], how=\"inner\")\n",
    "pca_std_pheno = []\n",
    "for i, df in enumerate(pca_cov):\n",
    "    df = pheno.join(pca_cov[i], how='inner').join(z12_swapped[i], how='inner')\n",
    "    print(df.shape)\n",
    "    pca_std_pheno.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, d in enumerate([ni_dir, imp_dir]):\n",
    "    save_df(d, \"z12_df\", z12_dfs[i])\n",
    "    save_df(d, \"z12_swapped\", z12_swapped[i])\n",
    "    save_df(d, \"pca_std\", pca_std[i])\n",
    "    save_df(d, \"pca_std_data\", pca_std_data[i])\n",
    "    save_df(d, \"mafs\", mafs[i])\n",
    "    save_df(d, \"allele_freqs\", allele_freqs[i])\n",
    "    save_df(d, \"pca_x\", pca_x[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pop_allele_data = []\n",
    "\n",
    "for i, df in enumerate(z12_swapped):\n",
    "    pop_data = {}\n",
    "    for group, data in df.groupby('population'):\n",
    "        data = data.drop(['population', 'popid'], axis=1)\n",
    "        print(i, group, data.shape)\n",
    "        gt = data.apply(get_allele_freqs, debug=False)\n",
    "        pop_data[group] = gt.to_dict()\n",
    "    pop_allele_data.append(pop_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, d in enumerate([ni_dir, imp_dir]):\n",
    "    pickle.dump(pop_allele_data[i], \n",
    "                open(os.path.join(d, \"pop_allele_data.pkl\"), \"wb\"), \n",
    "                protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_x[0].head(), pca_x[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_x_merge = pd.merge(pca_x[0], pca_x[1], suffixes=(\"_ni\", \"_imp\"), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp.stats.linregress(pca_x_merge.PC1_ni, pca_x_merge.PC1_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(pca_x_merge.PC1_ni, pca_x_merge.PC1_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
