{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../include_utils\")\n",
    "\n",
    "#from IPython.parallel import Client\n",
    "import ipyparallel as ipp\n",
    "import os, time\n",
    "import include_utils as u\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import vcf\n",
    "from sklearn import preprocessing\n",
    "from subprocess import Popen, PIPE\n",
    "import seaborn as sns\n",
    "from IPython.display import FileLink\n",
    "import urllib.request as urllib2\n",
    "import dill\n",
    "import traceback\n",
    "from pandas import Series, DataFrame\n",
    "import gzip\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from collections import OrderedDict, namedtuple\n",
    "import operator\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_r():\n",
    "    os.environ['R_HOME'] = '/home/cfriedline/g/R3/lib64/R'\n",
    "    os.environ['LD_LIBRARY_PATH'] = \"%s/lib:%s:%s\" % (os.environ['R_HOME'], \n",
    "                                                   os.environ['LD_LIBRARY_PATH'],\n",
    "                                                     \"/home/cfriedline/lib64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setup_r() #skip on mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "r = robjects.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "#%reload_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_GQ_to_p(q):\n",
    "    return pow(10,(q/-10.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vcfutils = \"perl /home/cfriedline/g/src/bcftools-1.3/vcfutils.pl\"\n",
    "vcftools = \"/home/cfriedline/bin/vcftools\"\n",
    "bcftools = \"/home/cfriedline/gpfs/src/bcftools-1.3/bcftools\"\n",
    "tabix = \"/home/cfriedline/gpfs/src/htslib-1.3/tabix\"\n",
    "bgzip = \"/home/cfriedline/gpfs/src/htslib-1.3/bgzip\"\n",
    "java  = \"/home/cfriedline/g/src/jdk1.8.0_60/bin/java\"\n",
    "plink = \"/home/cfriedline/g/src/plink-1.07-x86_64/plink --noweb\"\n",
    "plink2 = \"/home/cfriedline/g/src/plink_beta_3.29/plink\"\n",
    "vcfap = \"/home/cfriedline/g/src/vcflib/bin/vcfallelicprimitives\"\n",
    "\n",
    "# For Mac\n",
    "# vcfutils = \"perl /Users/chris/src/bcftools-1.3/vcfutils.pl\"\n",
    "# vcftools = \"/Users/chris/bin/vcftools\"\n",
    "# bcftools = \"/Users/chris/src/bcftools-1.3/bcftools\"\n",
    "# tabix = \"/Users/chris/src/htslib-1.3/tabix\"\n",
    "# bgzip = \"/Users/chris/src/htslib-1.3/bgzip\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done by dDocent, to create Final.recode.vcf\n",
    "\n",
    "```\n",
    "$ head -n20 logfiles/Final.log\n",
    "\n",
    "VCFtools - v0.1.11\n",
    "(C) Adam Auton 2009\n",
    "\n",
    "Parameters as interpreted:\n",
    "        --vcf TotalRawSNPs.vcf\n",
    "        --recode-INFO-all\n",
    "        --mac 1\n",
    "        --max-non-ref-af 1\n",
    "        --minQ 30\n",
    "        --geno 0.9\n",
    "        --non-ref-af 0.001\n",
    "        --counts\n",
    "        --out Final\n",
    "        --recode\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis_dir = \"/home/cfriedline/eckertlab/Mitra/dDocent\"\n",
    "vcf_file = os.path.join(analysis_dir, \"TotalRawSNPs.vcf\")\n",
    "assert os.path.exists(vcf_file)\n",
    "vcf_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc = ipp.Client(profile=\"sge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dv = rc[:]\n",
    "lv = rc.load_balanced_view()\n",
    "len(dv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {}
   },
   "source": [
    "## Decompose into SNPs and Indels\n",
    "`vcfallelicprimitives -k -g TotalRawSNPs.vcf > TotalRawSNPs.vcf.prim.vcf`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove indels and keep only biallelic snps with 50% data and MAF > 0.01, quality >20, minor allele count of 2\n",
    "\n",
    "```\n",
    "vcftools \\\n",
    "--vcf TotalRawSNPs.vcf.prim.vcf \\\n",
    "--remove-indels \\\n",
    "--mac 2 \\\n",
    "--minQ 20 \\\n",
    "--min-alleles 2 \\\n",
    "--max-alleles 2 \\\n",
    "--max-missing 0.5 \\\n",
    "--remove-filtered-all \\\n",
    "--recode \\\n",
    "--recode-INFO-all \\\n",
    "--out phase1\n",
    "```\n",
    "\n",
    "```\n",
    "Parameters as interpreted:\n",
    "        --vcf TotalRawSNPs.vcf.prim.vcf\n",
    "        --recode-INFO-all\n",
    "        --mac 2\n",
    "        --max-alleles 2\n",
    "        --min-alleles 2\n",
    "        --minQ 20\n",
    "        --max-missing 0.5\n",
    "        --out phase1\n",
    "        --recode\n",
    "        --remove-filtered-all\n",
    "        --remove-indels\n",
    "\n",
    "After filtering, kept 381 out of 381 Individuals\n",
    "Outputting VCF file...\n",
    "After filtering, kept 291234 out of a possible 842773 Sites\n",
    "Run Time = 921.00 seconds\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## add contig info to VCF header\n",
    "ref = \"/home/cfriedline/eckertlab/Mitra/dDocent/reference.fasta\"\n",
    "from Bio import SeqIO\n",
    "lens = {}\n",
    "for rec in SeqIO.parse(ref, \"fasta\"):\n",
    "    lens[rec.name] = len(rec)\n",
    "    \n",
    "with open(\"/home/cfriedline/eckertlab/Mitra/dDocent/vcf_contigs.txt\", \"w\") as o:\n",
    "    for k in sorted(lens, key=lambda x: int(x.split(\"_\")[-1])):\n",
    "        v = lens[k]\n",
    "        ##contig=<ID=dDocent_Contig_518964,length=68>\n",
    "        o.write(\"##contig=<ID={},length={}>\\n\".format(k, v))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {}
   },
   "source": [
    "## add contigs to header\n",
    "`bcftools annotate -h vcf_contigs.txt phase1.recode.vcf.gz | bgzip -c > phase1.recode.vcf.contig.vcf.gz`\n",
    "`tabix phase1.recode.vcf.contig.vcf.gz`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats with `vt`\n",
    "```\n",
    "~/g/src/vt/vt peek phase1.recode.vcf.contig.vcf.gz\n",
    "```\n",
    "\n",
    "### output\n",
    "```\n",
    "stats: no. of samples                     :        381\n",
    "       no. of chromosomes                 :      18366\n",
    "\n",
    "       ========== Micro variants ==========\n",
    "\n",
    "       no. of SNP                         :     291234\n",
    "           2 alleles                      :          291234 (1.62) [180096/111138]\n",
    "\n",
    "       no. of micro variants              :     291234\n",
    "\n",
    "       ++++++ Other useful categories +++++\n",
    "\n",
    "\n",
    "       ========= General summary ==========\n",
    "\n",
    "       no. of VCF records                        :     291234\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Export 012 file\n",
    "```\n",
    "vcftools \\\n",
    "--gzvcf phase1.recode.vcf.contig.vcf.gz \\\n",
    "--out phase1.recode.vcf.contig.vcf.gz \\\n",
    "--012\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phase1_vcf = os.path.join(analysis_dir, \"phase1.recode.vcf.contig.vcf.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z12_file = os.path.join(analysis_dir, \"phase1.recode.vcf.contig.vcf.gz.012\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_data = []\n",
    "for i, line in enumerate(open(z12_file)):\n",
    "    z12_data.append(line.strip().split(\"\\t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indv_file = \"{}.indv\".format(z12_file)\n",
    "pos_file = \"{}.pos\".format(z12_file)\n",
    "z12_df = pd.DataFrame(z12_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df = z12_df.drop(0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df.index = [x.strip() for x in open(indv_file).readlines()]\n",
    "z12_df.columns = [\"-\".join(x.strip().split(\"\\t\")) for x in open(pos_file).readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "def get_MAF(row):\n",
    "    try:\n",
    "        return np.min([row.A1_freq, row.A2_freq])\n",
    "    except:\n",
    "        print(row)\n",
    "        \n",
    "def get_correction(n):\n",
    "    #for finite sample size\n",
    "    return (2*n)/(2*n-1)\n",
    "\n",
    "def calculate_Fis(vals):\n",
    "    try:\n",
    "        data = [float(x) for x in vals.split(\"/\")]\n",
    "        assert len(data) == 3\n",
    "        num_individuals = np.sum(data)\n",
    "        total_alleles = 2*num_individuals\n",
    "        a1_count = 2*data[0]\n",
    "        a2_count = 2*data[2]\n",
    "        het_count = data[1]\n",
    "        a1_count += het_count\n",
    "        a2_count += het_count\n",
    "        a1_freq = a1_count/total_alleles\n",
    "        a2_freq = a2_count/total_alleles\n",
    "        assert a1_freq + a2_freq == 1.0\n",
    "        He = 2 * a1_freq * a2_freq * get_correction(num_individuals)\n",
    "        Ho = het_count/num_individuals\n",
    "        Fis = 1 - (Ho/He)\n",
    "        return Fis\n",
    "    except:\n",
    "        return -9\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_vcf_stats(vcf_gz):\n",
    "    \n",
    "    stats = ['depth',\n",
    "            'site-depth',\n",
    "            'site-mean-depth',\n",
    "            'site-quality',\n",
    "            'missing-indv',\n",
    "            'missing-site',\n",
    "            'freq',\n",
    "            'counts',\n",
    "            'hardy',\n",
    "            'het']\n",
    "    \n",
    "    for stat in stats:\n",
    "        !$vcftools --gzvcf $vcf_gz \\\n",
    "        --out $vcf_gz \\\n",
    "        {\"--%s\" % stat} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_vcf_stats(filedir, prefix):\n",
    "    hardy_files = !ls {filedir}/{prefix}*.hwe\n",
    "    hardy = pd.read_csv(hardy_files[0], sep=\"\\t\")\n",
    "\n",
    "    hardy.columns = ['CHROM', 'POS', 'OBS(HOM1/HET/HOM2)', 'E(HOM1/HET/HOM2)', 'ChiSq_HWE',\n",
    "       'P_HWE', 'P_HET_DEFICIT', 'P_HET_EXCESS']\n",
    "    hardy.index = hardy.apply(lambda x: \"%s-%d\" % (x.CHROM, x.POS), axis=1)\n",
    "    \n",
    "    loci_files = !ls {filedir}/{prefix}*.l* | grep -v log\n",
    "    loci_df = pd.concat([pd.read_csv(x, sep=\"\\t\", skiprows=0) for x in loci_files], axis=1)\n",
    "    chrom_pos = loci_df.ix[:,0:2]\n",
    "    \n",
    "    frq_files = !ls {filedir}/{prefix}*.frq* | grep -v count\n",
    "    frq_data = []\n",
    "    h = open(frq_files[0])\n",
    "    header = h.readline().strip().split()\n",
    "    for line in h:\n",
    "        frq_data.append(line.strip().split('\\t'))\n",
    "\n",
    "    header = ['CHROM', 'POS', 'N_ALLELES', 'N_CHR', 'A1_FREQ', \"A2_FREQ\"]\n",
    "    frq_df = pd.DataFrame(frq_data)\n",
    "    print(frq_df.columns)\n",
    "    #frq_df = frq_df.drop([6,7],axis=1)\n",
    "    frq_df.columns = header\n",
    "    frq_df.index = frq_df.apply(lambda x: \"%s-%s\" % (x.CHROM, x.POS), axis=1)\n",
    "    \n",
    "    loci_df = loci_df.drop(['CHROM','CHR','POS'], axis=1)\n",
    "    loci_df = pd.concat([chrom_pos, loci_df], axis=1)\n",
    "    loci_df.index = loci_df.apply(lambda x: \"%s-%d\" % (x.CHROM, x.POS), axis=1)\n",
    "    \n",
    "    loci_df = pd.concat([loci_df, frq_df, hardy], axis=1)\n",
    "    loci_df[\"A1_allele\"] = loci_df.apply(lambda row: row.A1_FREQ.split(\":\")[0], axis=1)\n",
    "    loci_df[\"A2_allele\"] = loci_df.apply(lambda row: row.A2_FREQ.split(\":\")[0], axis=1)\n",
    "    \n",
    "    loci_df[\"A1_freq\"] = loci_df.apply(lambda row: float(row.A1_FREQ.split(\":\")[1]), axis=1)\n",
    "    loci_df[\"A2_freq\"] = loci_df.apply(lambda row: float(row.A2_FREQ.split(\":\")[1]), axis=1)\n",
    "    \n",
    "    loci_df['MAF'] = loci_df.apply(get_MAF, axis=1)\n",
    "    loci_df = loci_df.drop(['CHROM', 'POS'], axis=1)\n",
    "    \n",
    "    loci_df['Fis'] = loci_df['OBS(HOM1/HET/HOM2)'].apply(calculate_Fis)\n",
    "    \n",
    "    return loci_df, frq_df, hardy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_vcf_stats(phase1_vcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_df, frq_df, hardy = combine_vcf_stats(analysis_dir, \"phase1.recode.vcf.contig.vcf.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute genotypes with beagle\n",
    "\n",
    "```bash\n",
    "cd /gpfs_fs/home/eckertlab/Mitra/mapping/split_parallel/collapsed/work/samtools1.3\n",
    "mkdir beagle40\n",
    "cd beagle40\n",
    "ln -s ../concat.vcf.gz_0.5.recode.vcf.gz\n",
    "java -jar ~/g/src/BEAGLE4/beagle.r1399.jar \\\n",
    "gl=concat.vcf.gz_0.5.recode.vcf.gz \\\n",
    "out=beagle40 \\\n",
    "nthreads=32 \\\n",
    "phase-its=20 \\\n",
    "burnin-its=20 \\\n",
    "impute-its=20\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beagle_dir = os.path.join(analysis_dir, \"beagle40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beagle_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beagle_vcf_gz = os.path.join(beagle_dir, \"beagle40.vcf.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "get_vcf_stats(beagle_vcf_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_df_beagle, freq_df_beagle, hardy_beagle = combine_vcf_stats(beagle_dir, \"beagle40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_df_beagle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chroms = sorted(set([x.split(\"-\")[0] for x in loci_df.index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(analysis_dir, \"chrom_map.txt\"), \"w\") as o:\n",
    "    for i, c in enumerate(chroms):\n",
    "        o.write(\"%s\\t%d\\n\" % (c, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def write_plink_files(vcf_gz):\n",
    "    !$vcftools --gzvcf {vcf_gz} \\\n",
    "    --out {vcf_gz} \\\n",
    "    --plink \\\n",
    "    --chrom-map {os.path.join(analysis_dir, \"chrom_map.txt\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_plink_files(phase1_vcf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_plink_recode(vcf_gz):\n",
    "    !$plink --recodeA --tab --file {vcf_gz} --out {vcf_gz}_recodeA\n",
    "    #!$plink --recode12 --tab --file {vcf_filtered_gz} --out {vcf_filtered_gz}_recode12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_plink_recode(vcf_filtered_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_df.SUM_DEPTH.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.distplot(loci_df.QUAL, hist=True, kde=False, bins=100)\n",
    "ax.set_xlim(0, 500000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loci_df.to_csv(os.path.join(analysis_dir, \"loci_stats.txt\"),\n",
    "              sep=\"\\t\",\n",
    "              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(loci_df[loci_df.Fis == -9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(loci_df[loci_df.QUAL >= 10]) - len(loci_df[loci_df.QUAL >= 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(loci_df[loci_df.QUAL < 20]), len(loci_df[loci_df.QUAL < 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(loci_df[loci_df.Fis >= 0.5]), len(loci_df[loci_df.Fis <= -0.5]), len(loci_df[loci_df.MAF < 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_snps(df, imputed=False):\n",
    "    if imputed:\n",
    "        return df[(df.MAF >= 0.01) & \n",
    "                  (df.Fis < 0.5) & \n",
    "                  (df.Fis > -0.5)]\n",
    "    else:\n",
    "        return df[(df.SUM_DEPTH >= 100) & \n",
    "                  (df.SUM_DEPTH < 1500) & \n",
    "                  (df.QUAL >= 20) & \n",
    "                  (df.MAF >= 0.01) & \n",
    "                  (df.Fis < 0.5) & \n",
    "                  (df.Fis > -0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_stage1 = filter_snps(loci_df)\n",
    "loci_stage1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beagle_stage1 = filter_snps(loci_df_beagle, imputed=True)\n",
    "beagle_stage1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(analysis_dir, \"stage1_positions.txt\"), \"w\") as o:\n",
    "    for elem in loci_stage1.index:\n",
    "        o.write(\"%s\\n\" % \"\\t\".join(elem.split(\"-\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "with open(os.path.join(beagle_dir, \"stage1_positions.txt\"), \"w\") as o:\n",
    "    for elem in beagle_stage1.index:\n",
    "        o.write(\"%s\\n\" % \"\\t\".join(elem.split(\"-\")))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#for d, vcf_gz in zip([analysis_dir, beagle_dir], [vcf_filtered_gz, beagle_vcf_gz]):\n",
    "for d, vcf_gz in zip([analysis_dir], [phase1_vcf]):\n",
    "    !$vcftools --gzvcf $vcf_gz \\\n",
    "    --remove-indels  \\\n",
    "    --remove-filtered-all \\\n",
    "    --recode \\\n",
    "    --recode-INFO-all \\\n",
    "    --positions {os.path.join(d, \"stage1_positions.txt\")} \\\n",
    "    --out {os.path.join(d, \"good_snps\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for d in [analysis_dir, beagle_dir]:\n",
    "for d in [analysis_dir]:\n",
    "    snps = os.path.join(d, \"good_snps.recode.vcf\")\n",
    "    snps_gz = snps + \".gz\"\n",
    "    !$bgzip -c {snps} > {snps_gz}\n",
    "    !$tabix {snps_gz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_intersection(imp, ni):\n",
    "    return set.intersection(set(ni.index), set(imp.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isect = get_intersection(beagle_stage1, loci_stage1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isect = sorted(isect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(loci_stage1.index), len(beagle_stage1.index), len(isect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for d in [analysis_dir, beagle_dir]:\n",
    "    with open(os.path.join(d, \"isect_positions.txt\"), \"w\") as o:\n",
    "        for elem in isect:\n",
    "            o.write(\"%s\\n\" % \"\\t\".join(elem.split(\"-\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d, vcf_gz in zip([analysis_dir, beagle_dir], [vcf_filtered_gz, beagle_vcf_gz]):\n",
    "    !$vcftools --gzvcf $vcf_gz \\\n",
    "    --remove-indels  \\\n",
    "    --remove-filtered-all \\\n",
    "    --recode \\\n",
    "    --recode-INFO-all \\\n",
    "    --positions {os.path.join(d, \"isect_positions.txt\")} \\\n",
    "    --out {os.path.join(d, \"isect_snps\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in [analysis_dir, beagle_dir]:\n",
    "    snps = os.path.join(d, \"isect_snps.recode.vcf\")\n",
    "    snps_gz = snps + \".gz\"\n",
    "    !$bgzip -c {snps} > {snps_gz}\n",
    "    !$tabix {snps_gz}\n",
    "    \n",
    "    srted = snps_gz + \"_sorted.vcf\"\n",
    "    srted_gz = srted + \".gz\"\n",
    "    !vcf-sort {snps_gz} > {srted}\n",
    "    !$bgzip -c {srted} > {srted_gz}\n",
    "    !$tabix {srted_gz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for d in [analysis_dir, beagle_dir]:\n",
    "    f = os.path.join(d, \"isect_snps.recode.vcf.gz_sorted.vcf.gz\")\n",
    "    assert os.path.exists(f)\n",
    "    write_plink_files(f)\n",
    "    write_plink_recode(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for d in [analysis_dir, beagle_dir]:\n",
    "    f = os.path.join(d, \"isect_snps.recode.vcf.gz_sorted.vcf.gz\")\n",
    "    !$vcftools --gzvcf {f} \\\n",
    "    --out {f} \\\n",
    "    --012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!grep -c \">\" /home/cfriedline/eckertlab/SugarPine_genome/pila.v1.0.scafSeq_mapped.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export file with alleles\n",
    "```\n",
    "zcat isect_snps.recode.vcf.gz_sorted.vcf.gz | ~/g/src/vcftools-0.1.14/src/perl/vcf-to-tab > isect_snps.recode.vcf.gz_sorted.vcf.gz.tab\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw = pd.read_csv(\"/gpfs_fs/home/eckertlab/Mitra/mapping/split_parallel/collapsed/work/samtools1.3/beagle40/isect_snps.recode.vcf.gz_sorted.vcf.gz_recodeA.raw\",\n",
    "                 sep=\"\\t\", header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
